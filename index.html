<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>
  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EMORL-TTS DEMO</title>
  <link rel="icon" type="image/x-icon" href="static/images/logo4.76133485.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <style>
    body {
      font-size: 18px;
    }
    .audio-section {
      width: 100%;
      padding-bottom: 1rem;
    }
    .table-wrapper {
      overflow-x: auto;
      width: 100%;
      margin-bottom: 2rem;
    }
    .table-wrapper table {
      width: max-content;
      margin: 0 auto;
      text-align: center;
    }
    .section p,
    .audio-section p,
    .content p {
      text-align: left;
      margin-bottom: 1.5rem;
    }
    .table thead th,
    .table tbody td {
      text-align: center;
      vertical-align: middle;
      white-space: nowrap;
    }
    audio {
      width: 265px;
    }
  </style>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<!-- Academic Project Page Template 保留顶部样式和字体 -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EMORL-TTS: Reinforcement Learning for Fine-Grained Emotion Control in LLM-based TTS</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="#">Haoxun Li</a>, </span>
            <span class="author-block"><a href="#">Leyuan Qu</a><sup>*</sup>, </span>
            <span class="author-block"><a href="#">Jiaxi Hu</a>, </span>
            <span class="author-block"><a href="#">Taihao Li</a><sup>*</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Hangzhou Institute for Advanced Study, University of Chinese Academy of Sciences, China<br>Under Review</span>
            <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding author</small></span>
          </div>
          <!--
          <div class="publication-links">
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper</span>
              </a>
            </span>
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                <span>arXiv</span>
              </a>
            </span>
          </div>
          -->
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In recent years, emotional Text-to-Speech (TTS) synthesis and emphasis-controllable speech synthesis have advanced significantly. However, their interaction remains underexplored. We propose Emphasis Meets Emotion TTS (EME-TTS), a novel framework designed to address two key research questions: (1) how to effectively utilize emphasis to enhance the expressiveness of emotional speech, and (2) how to maintain the perceptual clarity and stability of target emphasis across different emotions. EME-TTS employs weakly supervised learning with emphasis pseudo-labels and variance-based emphasis features. Additionally, the proposed Emphasis Perception Enhancement (EPE) block enhances the interaction between emotional signals and emphasis positions. Experimental results show that EME-TTS, when combined with large language models for emphasis position prediction, enables more natural emotional speech synthesis while preserving stable and distinguishable target emphasis across emotions.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Section 1: Emphasis Accuracy -->
<section class="section">
  <div class="audio-section container is-max-desktop has-text-centered">
    <h2 class="title is-3">1. Emphasis Accuracy</h2>
    <p>We designed a more challenging subjective test, distinct from previous studies on emphasis control. Instead of rating the degree of emphasis at a predefined position, participants were asked to identify the emphasized words in 80 randomly shuffled speech samples. The results indicate that the emphasis produced by our proposed model was clearly perceivable across different emotions.</p>

    <h3 class="title is-5">Sentence 1: She is now choosing skirt to wear.</h3>
    <div class="table-wrapper">
      <table class="table is-bordered is-fullwidth is-centered">
        <thead>
          <tr>
            <th>Emotion</th>
            <th>Emphasized Word</th>
            <th>EME-TTS w/o EPE</th>
            <th>EME-TTS</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>Neutral</td><td>choosing</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/SH_IY1_IH0_Z_N_0_8_6_10.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/SH_IY1_IH0_Z_N_0_8_6_10.wav"></audio></td></tr>
          <tr><td>Angry</td><td>now</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/SH_IY1_IH0_Z_N_1_8_4_5.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/SH_IY1_IH0_Z_N_1_8_4_5.wav"></audio></td></tr>
          <tr><td>Happy</td><td>choosing</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/SH_IY1_IH0_Z_N_2_8_6_10.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/SH_IY1_IH0_Z_N_2_8_6_10.wav"></audio></td></tr>
          <tr><td>Sad</td><td>wear</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/SH_IY1_IH0_Z_N_3_8_17_19.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/SH_IY1_IH0_Z_N_3_8_17_19.wav"></audio></td></tr>
          <tr><td>Surprise</td><td>skirt</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/SH_IY1_IH0_Z_N_4_8_11_14.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/SH_IY1_IH0_Z_N_4_8_11_14.wav"></audio></td></tr>
        </tbody>
      </table>
    </div>

    <h3 class="title is-5">Sentence 2: Must a name mean something?</h3>
    <div class="table-wrapper">
      <table class="table is-bordered is-fullwidth is-centered">
        <thead>
          <tr>
            <th>Emotion</th>
            <th>Emphasized Word</th>
            <th>EME-TTS w/o EPE</th>
            <th>EME-TTS</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>Neutral</td><td>mean</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/M_AH1_S_T_AH0_0_8_8_10.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/M_AH1_S_T_AH0_0_8_8_10.wav"></audio></td></tr>
          <tr><td>Angry</td><td>must</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/M_AH1_S_T_AH0_1_8_0_3.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/M_AH1_S_T_AH0_1_8_0_3.wav"></audio></td></tr>
          <tr><td>Happy</td><td>name</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/M_AH1_S_T_AH0_2_8_5_7.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/M_AH1_S_T_AH0_2_8_5_7.wav"></audio></td></tr>
          <tr><td>Sad</td><td>mean</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/M_AH1_S_T_AH0_3_8_8_10.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/M_AH1_S_T_AH0_3_8_8_10.wav"></audio></td></tr>
          <tr><td>Surprise</td><td>something</td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/M_AH1_S_T_AH0_4_8_11_16.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/M_AH1_S_T_AH0_4_8_11_16.wav"></audio></td></tr>
        </tbody>
      </table>
    </div>
  </div>
</section>

<!-- Section 2: Emotion Accuracy -->
<section class="section">
  <div class="audio-section container is-max-desktop has-text-centered">
    <h2 class="title is-3">2. Emotion Accuracy</h2>
    <p>To ensure fairness, all CosyVoice2-generated samples were conditioned on a neutral reference speaker's audio and a textual emotion prompt, ensuring that only the speaker's identity and emotion labels were provided as input. During inference, our proposed model consistently utilized a large language model to predict suitable emphasis positions, which were then used as input for testing. Results demonstrate that EME-TTS achieves higher emotion accuracy in synthesized speech compared to baseline models, highlighting its overall effectiveness in generating emotionally expressive speech.</p>

    <h3 class="title is-5">Sentence 1: I chose the right way.</h3>
    <div class="table-wrapper">
      <table class="table is-bordered is-fullwidth is-centered">
        <thead>
          <tr>
            <th>Emotion</th>
            <th>Emphasized Word</th>
            <th>CosyVoice2</th>
            <th>EmoSpeech</th>
            <th>EME-TTS w/o EPE</th>
            <th>EME-TTS</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>Neutral</td><td>right</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_10.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_41_0.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/AY1_CH_OW1_Z_DH_0_8_6_8.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/AY1_CH_OW1_Z_DH_0_8_6_8.wav"></audio></td></tr>
          <tr><td>Angry</td><td>right</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_11.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_41_1.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/AY1_CH_OW1_Z_DH_1_8_6_8.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/AY1_CH_OW1_Z_DH_1_8_6_8.wav"></audio></td></tr>
          <tr><td>Happy</td><td>right</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_12.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_41_2.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/AY1_CH_OW1_Z_DH_2_8_6_8.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/AY1_CH_OW1_Z_DH_2_8_6_8.wav"></audio></td></tr>
          <tr><td>Sad</td><td>way</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_13.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_41_3.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/AY1_CH_OW1_Z_DH_3_8_9_10.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/AY1_CH_OW1_Z_DH_3_8_9_10.wav"></audio></td></tr>
          <tr><td>Surprise</td><td>chose</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_14.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_41_4.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/AY1_CH_OW1_Z_DH_4_8_1_3.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/AY1_CH_OW1_Z_DH_4_8_1_3.wav"></audio></td></tr>
        </tbody>
      </table>
    </div>
    <h3 class="title is-5">Sentence 2: Rabbit gave dog a hurrying up sort of nudge.</h3>
    <div class="table-wrapper">
      <table class="table is-bordered is-fullwidth is-centered">
        <thead>
          <tr>
            <th>Emotion</th>
            <th>Emphasized Word</th>
            <th>CosyVoice2</th>
            <th>EmoSpeech</th>
            <th>EME-TTS w/o EPE</th>
            <th>EME-TTS</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>Neutral</td><td>gave</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_15.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_50_0.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/R_AE1_B_AH0_T_0_8_5_7.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/R_AE1_B_AH0_T_0_8_5_7.wav"></audio></td></tr>
          <tr><td>Angry</td><td>hurrying</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_16.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_50_1.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/R_AE1_B_AH0_T_1_8_12_16.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/R_AE1_B_AH0_T_1_8_12_16.wav"></audio></td></tr>
          <tr><td>Happy</td><td>nudge</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_17.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_50_2.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/R_AE1_B_AH0_T_2_8_25_27.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/R_AE1_B_AH0_T_2_8_25_27.wav"></audio></td></tr>
          <tr><td>Sad</td><td>nudge</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_18.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_50_3.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/R_AE1_B_AH0_T_3_8_25_27.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/R_AE1_B_AH0_T_3_8_25_27.wav"></audio></td></tr>
          <tr><td>Surprise</td><td>hurrying</td><td><audio controls src="static/some_test_audio/cosyvoice2/instruct_19.wav"></audio></td><td><audio controls src="static/some_test_audio/emospeech/8_50_4.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS without EPE/R_AE1_B_AH0_T_4_8_12_16.wav"></audio></td><td><audio controls src="static/some_test_audio/EME-TTS/R_AE1_B_AH0_T_4_8_12_16.wav"></audio></td></tr>
        </tbody>
      </table>
    </div>
  </div>
</section>

<!-- Section 3: Improvement of Emotional Expressiveness Through Emphasis -->
<section class="section">
  <div class="audio-section container is-max-desktop has-text-centered">
    <h2 class="title is-3">3. Improvement of Emotional Expressiveness Through Emphasis</h2>
    <p>Participants evaluated 30 sets of speech samples, each containing outputs from four models, based on perceived emotional expressiveness. Among them, 10 sets were derived from a short passage with contextual information. Within each set, samples were ranked from 1 (least expressive) to 4 (most expressive). The results indicate that EME-TTS consistently received the highest rankings, especially in the contextualized setting. This suggests that surrounding linguistic context strengthens the semantic foundation for emphasis, further enhancing emotional expressiveness.<br>
    <br>Short passage (10 sets): <br>
    1. Emma stepped outside and found a small box on her doorstep. (Surprise)<br>
    2. She stared at it trying to remember if she had ordered anything. (Neutral)<br>
    3. A folded note inside had nothing written. (Neutral)<br>
    4. She lifted the lid and gasped as a silver bracelet shimmered in the light. (Surprise)<br>
    5. It looked exactly like the one her grandmother used to wear. (Sad)<br>
    6. She traced the patterns on it remembering how she had lost it long ago. (Sad)<br>
    7. She looked around wondering who could have left it there and why. (Angry)<br>
    8. Her heart pounded as frustration bubbled inside her chest. (Angry)<br>
    9. Then warmth filled her as she held the bracelet tightly and smiled. (Happy)<br>
    10. She placed it on her wrist feeling as if her grandmother was near once more. (Happy) </p>
    <div class="table-wrapper">
      <table class="table is-bordered is-fullwidth is-centered">
        <thead>
          <tr>
            <th>Sentence</th>
            <th>Emphasized Word</th>
            <th>CosyVoice2</th>
            <th>EmoSpeech</th>
            <th>EME-TTS w/o EPE</th>
            <th>EME-TTS</th>
          </tr>
        </thead>
        <tbody>
          <tr><td>Sentence 1</td><td>small</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_0.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/1.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/1_EH1_M_AH0_S_T_4_8_21_24.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/1_EH1_M_AH0_S_4_8_21_24.wav"></audio></td></tr>
          <tr><td>Sentence 2</td><td>remember</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_1.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/2.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/2_SH_IY1_S_T_EH1_0_8_18_24.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/2_SH_IY1_S_T_EH1_0_8_18_24.wav"></audio></td></tr>
          <tr><td>Sentence 3</td><td>nothing</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_2.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/3.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/3_AH0_F_OW1_L_D_0_8_18_22.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/3_AH0_F_OW1_L_D_0_8_18_22.wav"></audio></td></tr>
          <tr><td>Sentence 4</td><td>bracelet</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_3.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/4.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/4_SH_IY1_L_IH1_F_4_8_29_35.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/4_SH_IY1_L_IH1_F_4_8_29_35.wav"></audio></td></tr>
          <tr><td>Sentence 5</td><td>wear</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_4.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/5.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/5_IH1_T_L_UH1_K_3_8_37_41.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/5_IH1_T_L_UH1_K_3_8_39_41.wav"></audio></td></tr>
          <tr><td>Sentence 6</td><td>lost</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_5.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/6.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/6_SH_IY1_T_R_EY1_3_8_35_38.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/6__SH_IY1_T_R_3_8_35_38.wav"></audio></td></tr>
          <tr><td>Sentence 7</td><td>left</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_6.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/7.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/7_SH_IY1_L_UH1_K_1_8_26_29.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/7_SH_IY1_L_UH1_K_1_8_26_29.wav"></audio></td></tr>
          <tr><td>Sentence 8</td><td>pounded</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_7.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/8.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/8_HH_ER0_HH_AA1_R_1_8_6_11.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/8_HH_ER0_HH_AA1_R_1_8_6_11.wav"></audio></td></tr>
          <tr><td>Sentence 9</td><td>smiled</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_8.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/9.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/9_DH_EH1_N_W_AO1_2_8_39_43.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/9_DH_EH1_N_W_AO1_2_8_39_43.wav"></audio></td></tr>
          <tr><td>Sentence 10</td><td>near</td><td><audio controls src="static/shortpassage/cosyvoice2/instruct_9.wav"></audio></td><td><audio controls src="static/shortpassage/emospeech/10.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS without EPE/10_SH_IY1_P_L_EY1_2_8_40_42.wav"></audio></td><td><audio controls src="static/shortpassage/EME-TTS/10_SH_IY1_P_L_EY1_2_8_40_42.wav"></audio></td></tr>
        </tbody>
      </table>
    </div>
  </div>
</section>
<p class="has-text-centered mt-5">Thanks for your patience!<br><br><br><br><br></p>